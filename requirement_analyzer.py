import os
import json
import re
import logging
from enum import Enum
from typing import List, Optional
from pydantic import BaseModel, Field, ValidationError
from openai import OpenAI
from dotenv import load_dotenv

# Logging yapÄ±landÄ±rmasÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('requirement_analyzer.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# BÃ–LÃœM 1: VERÄ° MODELLERÄ°
# ==========================================

class CVTaskType(str, Enum):
    DETECTION = "object_detection"       # Nesne Tespiti
    CLASSIFICATION = "classification"    # SÄ±nÄ±flandÄ±rma
    SEGMENTATION = "segmentation"        # BÃ¶lÃ¼tleme
    OCR = "optical_character_recognition" # YazÄ± Okuma
    ANOMALY_DETECTION = "anomaly_detection" # Anomali Tespiti

class EnvironmentType(str, Enum):
    INDOOR_CONTROLLED = "indoor_controlled" 
    INDOOR_VARIABLE = "indoor_variable"    
    OUTDOOR_DAY = "outdoor_day"            
    OUTDOOR_NIGHT = "outdoor_night"        
    UNDERWATER = "underwater"              

class DeploymentType(str, Enum):
    EDGE = "edge_device"       # Raspberry Pi, Jetson
    CLOUD = "cloud_api"        # Sunucu
    HYBRID = "hybrid"          # Hibrit

class CameraSpecs(BaseModel):
    resolution_width: int = Field(
        1920, description="Kamera Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ geniÅŸlik (piksel). Ã–rn: 1920, 1280, 640"
    )
    resolution_height: int = Field(
        1080, description="Kamera Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ yÃ¼kseklik (piksel). Ã–rn: 1080, 720, 480"
    )
    max_camera_fps: int = Field(
        30, description="KameranÄ±n desteklediÄŸi maksimum FPS deÄŸeri.", ge=1, le=240
    )
    lens_type: Optional[str] = Field(
        None, description="Lens tipi. Ã–rn: 'wide-angle', 'fisheye', 'telephoto', 'standard'"
    )
    is_color: bool = Field(
        True, description="Renkli kamera mÄ± yoksa monokrom mu?"
    )
    connection_type: Optional[str] = Field(
        None, description="BaÄŸlantÄ± tÃ¼rÃ¼. Ã–rn: 'USB', 'CSI', 'IP/RTSP', 'MIPI'"
    )
    sensor_type: Optional[str] = Field(
        None, description="SensÃ¶r tipi. Ã–rn: 'CMOS', 'CCD'"
    )

class HardwareConstraints(BaseModel):
    device_name: Optional[str] = Field(
        None, description="KullanÄ±cÄ±nÄ±n elindeki cihaz. Ã–rn: 'Raspberry Pi 5', 'Jetson Orin Nano'"
    )
    ram_gb: Optional[int] = Field(
        None, description="Mevcut RAM miktarÄ± (GB cinsinden). Ã–rn: 4, 8, 16", ge=1
    )
    storage_gb: Optional[int] = Field(
        None, description="Mevcut depolama alanÄ± (GB cinsinden). Ã–rn: 32, 64, 128, 256", ge=1
    )
    has_gpu: Optional[bool] = Field(
        None, description="Cihazda GPU var mÄ±? (CUDA, TensorRT, vb. iÃ§in Ã¶nemli)"
    )

class PerformanceMetrics(BaseModel):
    min_fps: int = Field(
        ..., description="Sistemin Ã§alÄ±ÅŸmasÄ± gereken minimum kare hÄ±zÄ± (FPS).", ge=1, le=120
    )
    max_latency_ms: int = Field(
        ..., description="Kabul edilebilir maksimum gecikme sÃ¼resi (milisaniye)."
    )

class VisionProjectRecipe(BaseModel):
    project_name: str = Field(..., description="Projenin kÄ±sa, teknik adÄ±. Ã–rn: 'traffic_counter_v1'")
    description: str = Field(..., description="Projenin ne yapacaÄŸÄ±nÄ±n 1-2 cÃ¼mlelik Ã¶zeti.")
    task_type: CVTaskType = Field(..., description="Projenin ana gÃ¶rÃ¼ntÃ¼ iÅŸleme gÃ¶revi.")
    target_objects: List[str] = Field(
        ..., 
        description="Tespit edilecek nesnelerin listesi. Ã–rn: ['araba', 'kamyon']",
        min_length=1 
    )
    environment: EnvironmentType = Field(..., description="KameranÄ±n Ã§alÄ±ÅŸacaÄŸÄ± ortam koÅŸullarÄ±.")
    deployment: DeploymentType = Field(..., description="Projenin Ã§alÄ±ÅŸacaÄŸÄ± platform (Edge/Cloud).")
    performance: PerformanceMetrics = Field(..., description="HÄ±z ve gecikme gereksinimleri.")
    camera: CameraSpecs = Field(
        default_factory=CameraSpecs,
        description="Kamera Ã¶zellikleri ve teknik spesifikasyonlarÄ±."
    )
    hardware: HardwareConstraints = Field(
        default_factory=HardwareConstraints,
        description="DonanÄ±m kÄ±sÄ±tlamalarÄ± ve tercihler."
    )
    suggested_model: Optional[str] = Field(
        None, description="LLM tarafÄ±ndan Ã¶nerilen model."
    )

# ==========================================
# BÃ–LÃœM 2: OPENAI AJAN MANTIÄI (DÃœZELTME) 
# ==========================================

class RecipeAgent:
    MAX_HISTORY_LENGTH = 20  # Maksimum konuÅŸma geÃ§miÅŸi sayÄ±sÄ± (system prompt hariÃ§)
    
    def __init__(self):
        # API key'i environment'tan gÃ¼venli ÅŸekilde oku
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key or api_key == "sk-your-api-key-here":
            logger.error("GeÃ§erli bir OPENAI_API_KEY bulunamadÄ±!")
            raise ValueError("GeÃ§erli bir OPENAI_API_KEY environment variable'Ä± gerekli.")
        
        self.client = OpenAI(api_key=api_key)
        self.history = []
        logger.info("RecipeAgent baÅŸarÄ±yla baÅŸlatÄ±ldÄ±.")
        
        # Pydantic ÅŸemasÄ±nÄ± LLM'in anlayacaÄŸÄ± JSON formatÄ±na Ã§eviriyoruz
        schema_json = VisionProjectRecipe.model_json_schema()
        
        self.system_prompt = f"""
Sen bir Senior Computer Vision Engineer'sÄ±n. âš ï¸ Ã–NEMLÄ°: KullanÄ±cÄ± gÃ¶rÃ¼ntÃ¼ iÅŸleme konusunda TEKNÄ°K BÄ°LGÄ°YE SAHÄ°P DEÄÄ°L!

ğŸ¯ GÃ–REV:
KullanÄ±cÄ±nÄ±n GÃœNLÃœK DÄ°LLE anlattÄ±ÄŸÄ± projeden maksimum bilgiyi Ã‡IKARSANABÄ°LDÄ°ÄÄ°NCE Ã‡OK Ã‡IKARIM YAP, mÃ¼mkÃ¼n olduÄŸunca AZ SORU SOR.

ğŸ“‹ TOPLANMASI GEREKEN BÄ°LGÄ°LER:

1. **Proje AmacÄ±**
   - Ne yapmak istiyor? (tespit, sayma, ayÄ±rt etme, okuma, hata bulma, vb.)
   - Hangi nesneler/durumlar Ã¼zerinde Ã§alÄ±ÅŸacak?
   â†’ Buradan Ã§Ä±kar: task_type, target_objects, project_name

2. **Ã‡alÄ±ÅŸma OrtamÄ±**
   - Nerede kullanÄ±lacak? (fabrika, yol, ofis, dÄ±ÅŸarÄ±, vb.)
   - IÅŸÄ±k koÅŸullarÄ± nasÄ±l? (sabit, deÄŸiÅŸken, gece/gÃ¼ndÃ¼z)
   â†’ Buradan Ã§Ä±kar: environment

3. **Performans Beklentileri**
   - HÄ±z Ã¶nemli mi? GerÃ§ek zamanlÄ± olmalÄ± mÄ±?
   - Gecikme tolere edilebilir mi?
   â†’ Buradan Ã§Ä±kar: min_fps, max_latency_ms

4. **Kamera Ã–zellikleri**
   - Hangi kamera kullanÄ±lacak? Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k? (Full HD, HD, dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k)
   - KameranÄ±n FPS deÄŸeri ne? (30fps, 60fps standart deÄŸerler)
   - Ã–zel lens tipi var mÄ±? (wide-angle, fisheye, normal)
   - BaÄŸlantÄ± tipi? (USB, CSI, IP kamera)
   â†’ Buradan Ã§Ä±kar: resolution_width, resolution_height, max_camera_fps, lens_type, connection_type

5. **DonanÄ±m ve Deployment**
   - Nerede Ã§alÄ±ÅŸacak? (kÃ¼Ã§Ã¼k cihaz, bilgisayar, sunucu)
   - Hangi cihaz varsa? (Raspberry Pi, Jetson, PC, vs.)
   - RAM ve depolama ne kadar? (4GB/8GB/16GB RAM, 32GB/64GB depolama)
   - GPU var mÄ±?
   â†’ Buradan Ã§Ä±kar: deployment (edge_device/cloud_api/hybrid), device_name, ram_gb, storage_gb, has_gpu

6. **Model Ã–nerisi**
   - YukarÄ±daki bilgilere gÃ¶re en uygun Computer Vision modelini SEN seÃ§.
   Model Ã¶nerirken sadece bilinen, yaygÄ±n ve 'Deployment Type' ile uyumlu modelleri  Ã¶ner.


ğŸ§  NASIL DAVRANMALISIN:

âœ… **YAP:**
- ğŸ”¥ Ä°LK MESAJDAN MAKSÄ°MUM Ã‡IKARIM YAP! 
- GÃ¼nlÃ¼k dil kullan, teknik terimlerden kaÃ§Ä±n
- TÃ¼m bilgiler toplandÄ±ÄŸÄ±nda "[REÃ‡ETE HAZIR]" yaz.

âŒ **YAPMA:**
- âŒ Teknik terimler kullanma (FPS, Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, latency, anomaly detection gibi)
- âŒ KullanÄ±cÄ±nÄ±n zaten promptunda bahsettiÄŸi ÅŸeyleri sorma


ğŸ¨ SEN KARAR VER:
âœ… KullanÄ±cÄ±nÄ±n anlattÄ±ÄŸÄ± projeden mantÄ±klÄ± Ã§Ä±karÄ±mlar yap.
âœ… Eksik teknik detaylarÄ± makul deÄŸerlerle SEN doldur
âœ… VarsayÄ±mlarÄ±nÄ± kullanÄ±cÄ±ya gÃ¼nlÃ¼k dille Ã¶zet olarak gÃ¶ster.
âœ… DONANIM ve MODEL seÃ§iminde NET ve SPESIFIK ol - belirsiz ifadeler kullanma!

ğŸ“Œ REÃ‡ETE HAZIR OLMADAN Ã–NCE KONTROL ET:
- âœ“ DonanÄ±m seÃ§imi spesifik mi? 
- âœ“ Model seÃ§imi net mi? 


JSON ÅEMASI:
{json.dumps(schema_json, indent=2)}

ğŸ”‘ Ã–NEMLÄ°:
- Sohbet sÄ±rasÄ±nda JSON dÃ¶ndÃ¼rme!
- TÃ¼m bilgiler tamamlanÄ±nca "[REÃ‡ETE HAZIR]" yaz.
- Sonraki adÄ±mda JSON oluÅŸturulacak.
"""
        
        self.history.append({"role": "system", "content": self.system_prompt})

    def _truncate_history(self):
        """KonuÅŸma geÃ§miÅŸini belirli bir uzunlukta tutar (system prompt korunur)."""
        if len(self.history) > self.MAX_HISTORY_LENGTH + 1:  # +1 for system prompt
            # System prompt'u koru, eski mesajlarÄ± sil
            system_prompt = self.history[0]
            self.history = [system_prompt] + self.history[-(self.MAX_HISTORY_LENGTH):]
            logger.info(f"KonuÅŸma geÃ§miÅŸi kÄ±rpÄ±ldÄ±. Mevcut uzunluk: {len(self.history)}")

    def _clean_json_string(self, json_string):
        """LLM bazen ```json ... ``` ÅŸeklinde markdown ekler, bunu temizler."""
        json_string = json_string.strip()
        # Markdown kod bloÄŸu kontrolÃ¼
        if json_string.startswith("```json"):
            json_string = json_string[7:]  # ```json kÄ±smÄ±nÄ± at
        elif json_string.startswith("```"):
            json_string = json_string[3:]  # ``` kÄ±smÄ±nÄ± at
        if json_string.endswith("```"):
            json_string = json_string[:-3]
        return json_string.strip()

    def chat(self, user_input: str):
        logger.info(f"KullanÄ±cÄ± giriÅŸi alÄ±ndÄ±: {user_input[:50]}..." if len(user_input) > 50 else f"KullanÄ±cÄ± giriÅŸi alÄ±ndÄ±: {user_input}")
        
        self.history.append({"role": "user", "content": user_input})
        self._truncate_history()  # GeÃ§miÅŸi kontrol et ve gerekirse kÄ±rp

        try:
            # âœ… response_format KULLANMIYORUZ - LLM'in doÄŸal sohbet etmesine izin veriyoruz
            logger.debug(f"OpenAI API'ye istek gÃ¶nderiliyor. History uzunluÄŸu: {len(self.history)}")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=self.history,
                temperature=0.3
            )
            
            ai_response = response.choices[0].message.content
            self.history.append({"role": "assistant", "content": ai_response})
            logger.info("OpenAI API yanÄ±tÄ± baÅŸarÄ±yla alÄ±ndÄ±.")
            
            # "[REÃ‡ETE HAZIR]" kontrolÃ¼
            if "[REÃ‡ETE HAZIR]" in ai_response or "[RECETE HAZIR]" in ai_response:
                logger.info("ReÃ§ete hazÄ±r sinyali alÄ±ndÄ±.")
                # KullanÄ±cÄ±ya bildir ve JSON iste
                return {
                    "status": "ready_for_json",
                    "message": ai_response,
                    "recipe": None
                }
            
            # Normal sohbet modunda devam et
            return {
                "status": "in_progress",
                "message": ai_response,
                "recipe": None
            }

        except Exception as e:
            logger.error(f"API HatasÄ±: {str(e)}", exc_info=True)
            return {"status": "error", "message": f"API HatasÄ±: {str(e)}"}

    def generate_recipe(self):
        """ReÃ§ete hazÄ±r olduÄŸunda bu fonksiyonu Ã§aÄŸÄ±r, JSON oluÅŸtur"""
        logger.info("JSON reÃ§etesi oluÅŸturma iÅŸlemi baÅŸlatÄ±ldÄ±.")
        try:
            # JSON Ã¼retimi iÃ§in Ã¶zel istek
            json_request = {
                "role": "user",
                "content": "Åimdi topladÄ±ÄŸÄ±n tÃ¼m bilgileri kullanarak VisionProjectRecipe JSON ÅŸemasÄ±na uygun bir JSON oluÅŸtur. SADECE JSON dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama yapma."
            }
            
            self.history.append(json_request)
            
            # âœ… Åimdi response_format kullanabiliriz Ã§Ã¼nkÃ¼ sadece JSON istiyoruz
            logger.debug("JSON formatÄ±nda yanÄ±t isteniyor...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=self.history,
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            json_response = response.choices[0].message.content
            cleaned_json = self._clean_json_string(json_response)
            logger.debug(f"TemizlenmiÅŸ JSON alÄ±ndÄ±: {cleaned_json[:100]}...")
            
            # JSON'u parse et ve validate et
            data = json.loads(cleaned_json)
            recipe = VisionProjectRecipe(**data)
            
            logger.info(f"ReÃ§ete baÅŸarÄ±yla oluÅŸturuldu: {recipe.project_name}")
            return {
                "status": "completed",
                "message": "âœ… ReÃ§ete baÅŸarÄ±yla oluÅŸturuldu ve doÄŸrulandÄ±!",
                "recipe": recipe
            }
            
        except (json.JSONDecodeError, ValidationError) as e:
            logger.error(f"JSON oluÅŸturma/doÄŸrulama hatasÄ±: {str(e)}", exc_info=True)
            return {
                "status": "error",
                "message": f"âŒ JSON oluÅŸturma hatasÄ±: {str(e)}\nLÃ¼tfen daha fazla detay verin.",
                "recipe": None
            }
        except Exception as e:
            logger.error(f"Beklenmeyen hata: {str(e)}", exc_info=True)
            return {"status": "error", "message": f"API HatasÄ±: {str(e)}"}

# ==========================================
# BÃ–LÃœM 3: Ã‡ALIÅTIRMA (MAIN LOOP)
# ==========================================

if __name__ == "__main__":
    try:
        agent = RecipeAgent()  # API key artÄ±k constructor iÃ§inde yÃ¶netiliyor
        logger.info("Uygulama baÅŸlatÄ±ldÄ±.")
        
        print("\nğŸ¤– GÃ–RÃœNTÃœ Ä°ÅLEME MÄ°MARI: Merhaba! Projenizden bahsedin, teknik detaylarÄ± belirleyelim.\n")
        print("Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basabilirsiniz.\n")
        
        while True:
            try:
                user_in = input("Siz: ")
            except (KeyboardInterrupt, EOFError):
                logger.info("KullanÄ±cÄ± uygulamadan Ã§Ä±ktÄ± (Ctrl+C).")
                print("\nGÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break

            if user_in.lower() in ["q", "exit", "Ã§Ä±k"]:
                logger.info("KullanÄ±cÄ± uygulamadan Ã§Ä±ktÄ±.")
                print("GÃ¶rÃ¼ÅŸÃ¼rÃ¼z!")
                break
            
            result = agent.chat(user_in)
            
            if result["status"] == "in_progress":
                print(f"\nğŸ¤– Mimar: {result['message']}\n")
            
            elif result["status"] == "ready_for_json":
                print(f"\nğŸ¤– Mimar: {result['message']}\n")
                print("âš™ï¸  JSON reÃ§etesi oluÅŸturuluyor...\n")
                
                # ReÃ§eteyi oluÅŸtur
                json_result = agent.generate_recipe()
                
                if json_result["status"] == "completed":
                    print(f"{json_result['message']}")
                    print("="*60)
                    recipe = json_result["recipe"]
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    print(f"ğŸ“ Proje: {recipe.project_name}")
                    print(f"ğŸ“ AÃ§Ä±klama: {recipe.description}")
                    print(f"ğŸ¯ GÃ¶rev: {recipe.task_type.name}")
                    print(f"ğŸ” Hedef Nesneler: {', '.join(recipe.target_objects)}")
                    print(f"ğŸŒ Ortam: {recipe.environment.name}")
                    print(f"ğŸš€ Platform: {recipe.deployment.name}")
                    print(f"âš¡ FPS Hedefi: {recipe.performance.min_fps}")
                    print(f"â±ï¸  Max Gecikme: {recipe.performance.max_latency_ms}ms")
                    print(f"\nğŸ“· KAMERA Ã–ZELLÄ°KLERÄ°:")
                    print(f"   Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: {recipe.camera.resolution_width}x{recipe.camera.resolution_height}")
                    print(f"   Max FPS: {recipe.camera.max_camera_fps}")
                    if recipe.camera.lens_type:
                        print(f"   Lens: {recipe.camera.lens_type}")
                    print(f"   Tip: {'Renkli' if recipe.camera.is_color else 'Monokrom'}")
                    if recipe.camera.connection_type:
                        print(f"   BaÄŸlantÄ±: {recipe.camera.connection_type}")
                    print(f"\nğŸ’» DONANIM:")
                    if recipe.hardware.device_name:
                        print(f"   Cihaz: {recipe.hardware.device_name}")
                    if recipe.hardware.ram_gb:
                        print(f"   RAM: {recipe.hardware.ram_gb} GB")
                    if recipe.hardware.storage_gb:
                        print(f"   Depolama: {recipe.hardware.storage_gb} GB")
                    if recipe.hardware.has_gpu is not None:
                        print(f"   GPU: {'Var' if recipe.hardware.has_gpu else 'Yok'}")
                    print(f"\nğŸ§  Ã–nerilen Model: {recipe.suggested_model}")
                    print("="*60)
                    
                    # JSON'u kaydet
                    output_file = f"{recipe.project_name}_recipe.json"
                    with open(output_file, "w", encoding="utf-8") as f:
                        json.dump(recipe.model_dump(), f, indent=2, ensure_ascii=False)
                    print(f"\nğŸ’¾ ReÃ§ete kaydedildi: {output_file}")
                    logger.info(f"ReÃ§ete dosyaya kaydedildi: {output_file}")
                    
                    break
                else:
                    print(f"âŒ {json_result['message']}")
            
            elif result["status"] == "error":
                print(f"âŒ Hata: {result['message']}")
                break
                
    except ValueError as e:
        print(f"âŒ {str(e)}")
        print("LÃ¼tfen .env dosyasÄ±ndaki OPENAI_API_KEY deÄŸiÅŸkenine geÃ§erli bir OpenAI anahtarÄ± girin.")
        exit(1)
